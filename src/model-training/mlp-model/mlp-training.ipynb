{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de75be1e",
   "metadata": {},
   "source": [
    "# Classificacao dos estagios do sono com MLP\n",
    "\n",
    "Este notebook organiza o pipeline de treino, validacao e teste para um perceptron multicamadas aplicado aos dados de estagios do sono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f49546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:17:22.802115Z",
     "iopub.status.busy": "2025-10-03T15:17:22.801308Z",
     "iopub.status.idle": "2025-10-03T15:17:59.185561Z",
     "shell.execute_reply": "2025-10-03T15:17:59.183111Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1794553",
   "metadata": {},
   "source": [
    "## Configuracao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad75a5fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:17:59.192499Z",
     "iopub.status.busy": "2025-10-03T15:17:59.191081Z",
     "iopub.status.idle": "2025-10-03T15:18:06.249687Z",
     "shell.execute_reply": "2025-10-03T15:18:06.246176Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = Path().resolve()\n",
    "if not (BASE_PATH / \"datalake\").exists():\n",
    "    BASE_PATH = BASE_PATH.parents[2]\n",
    "DATASETS_PATH = BASE_PATH / \"datalake\" / \"data-for-model\"\n",
    "TRAINING_DATA_FILE = DATASETS_PATH / \"train\" / \"train_sleep_cassette.parquet\"\n",
    "VALIDATION_DATA_FILE = DATASETS_PATH / \"val\" / \"val_sleep_cassette.parquet\"\n",
    "TEST_DATA_FILE = DATASETS_PATH / \"test\" / \"test_sleep_cassette.parquet\"\n",
    "STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "STAGE2ID = {stage: idx for idx, stage in enumerate(STAGES)}\n",
    "df_train = pd.read_parquet(TRAINING_DATA_FILE, engine=\"fastparquet\")\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_FILE, engine=\"fastparquet\")\n",
    "df_test = pd.read_parquet(TEST_DATA_FILE, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff2b3f",
   "metadata": {},
   "source": [
    "## Preparacao das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87db9b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:18:06.258148Z",
     "iopub.status.busy": "2025-10-03T15:18:06.256414Z",
     "iopub.status.idle": "2025-10-03T15:18:27.430224Z",
     "shell.execute_reply": "2025-10-03T15:18:27.426939Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "SEX_MAP = {\"F\": 0.0, \"M\": 1.0}\n",
    "frames = [df_train, df_val, df_test]\n",
    "for frame in frames:\n",
    "    frame[\"sex\"] = frame[\"sex\"].map(SEX_MAP).fillna(0.5).astype(np.float32)\n",
    "    frame[\"stage_id\"] = frame[\"stage\"].map(STAGE2ID).astype(np.int64)\n",
    "\n",
    "IDENTIFIERS = [\"subject_id\", \"night_id\", \"epoch_idx\", \"stage\", \"stage_id\"]\n",
    "FEATURES = [column for column in df_train.columns if column not in IDENTIFIERS]\n",
    "FEATURES.sort()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(df_train[FEATURES]).astype(np.float32)\n",
    "x_val = scaler.transform(df_val[FEATURES]).astype(np.float32)\n",
    "x_test = scaler.transform(df_test[FEATURES]).astype(np.float32)\n",
    "\n",
    "y_train = df_train[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_val = df_val[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_test = df_test[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "class_distribution = df_train[\"stage_id\"].value_counts().sort_index()\n",
    "base_weights = (len(df_train) / (len(STAGES) * class_distribution)).astype(np.float64)\n",
    "adjusted_weights = base_weights ** 1.15\n",
    "weight_lookup = {idx: float(adjusted_weights.loc[idx]) for idx in class_distribution.index}\n",
    "train_weights = np.array([weight_lookup[label] for label in y_train], dtype=np.float64)\n",
    "val_weights = np.array([weight_lookup.get(label, 1.0) for label in y_val], dtype=np.float64)\n",
    "test_weights = np.array([weight_lookup.get(label, 1.0) for label in y_test], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531aa55d",
   "metadata": {},
   "source": [
    "## Distribuicao das classes no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1aee960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:18:27.443546Z",
     "iopub.status.busy": "2025-10-03T15:18:27.442845Z",
     "iopub.status.idle": "2025-10-03T15:18:27.729337Z",
     "shell.execute_reply": "2025-10-03T15:18:27.727504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>samples</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>34935</td>\n",
       "      <td>0.309837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>13882</td>\n",
       "      <td>0.123119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2</td>\n",
       "      <td>40344</td>\n",
       "      <td>0.357809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3</td>\n",
       "      <td>8532</td>\n",
       "      <td>0.075670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REM</td>\n",
       "      <td>15060</td>\n",
       "      <td>0.133566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stage  samples  proportion\n",
       "0     W    34935    0.309837\n",
       "1    N1    13882    0.123119\n",
       "2    N2    40344    0.357809\n",
       "3    N3     8532    0.075670\n",
       "4   REM    15060    0.133566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_summary = pd.DataFrame({\n",
    "    \"stage\": STAGES,\n",
    "    \"samples\": [int(class_distribution.get(idx, 0)) for idx in range(len(STAGES))]\n",
    "})\n",
    "class_summary[\"proportion\"] = class_summary[\"samples\"] / class_summary[\"samples\"].sum()\n",
    "class_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe6c6e",
   "metadata": {},
   "source": [
    "## Datasets e carregadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9983c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:18:28.010066Z",
     "iopub.status.busy": "2025-10-03T15:18:28.009315Z",
     "iopub.status.idle": "2025-10-03T15:18:28.317405Z",
     "shell.execute_reply": "2025-10-03T15:18:28.315547Z"
    }
   },
   "outputs": [],
   "source": [
    "class SleepDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.from_numpy(features)\n",
    "        self.labels = torch.from_numpy(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n",
    "train_dataset = SleepDataset(x_train, y_train)\n",
    "val_dataset = SleepDataset(x_val, y_val)\n",
    "test_dataset = SleepDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 512\n",
    "num_workers = min(8, os.cpu_count() // 2) if os.cpu_count() else 2\n",
    "pin_memory = torch.cuda.is_available()\n",
    "persistent = num_workers > 0\n",
    "loader_args = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"pin_memory\": pin_memory,\n",
    "    \"persistent_workers\": persistent\n",
    "}\n",
    "if num_workers > 0:\n",
    "    loader_args[\"prefetch_factor\"] = 2\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, **loader_args)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, **loader_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c5650",
   "metadata": {},
   "source": [
    "## Modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f9a6e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:18:28.323194Z",
     "iopub.status.busy": "2025-10-03T15:18:28.321496Z",
     "iopub.status.idle": "2025-10-03T15:18:28.342224Z",
     "shell.execute_reply": "2025-10-03T15:18:28.338876Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, expansion, dropout):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(dim * expansion)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fc1 = nn.Linear(dim, hidden_dim)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        residual = inputs\n",
    "        outputs = self.norm(inputs)\n",
    "        outputs = self.fc1(outputs)\n",
    "        outputs = self.activation(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.fc2(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        return outputs + residual\n",
    "\n",
    "class SleepMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, depth, expansion, dropout, num_classes):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ]\n",
    "        self.stem = nn.Sequential(*layers)\n",
    "        self.blocks = nn.ModuleList([ResidualBlock(hidden_dim, expansion, dropout) for _ in range(depth)])\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.stem(inputs)\n",
    "        for block in self.blocks:\n",
    "            outputs = block(outputs)\n",
    "        return self.head(outputs)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=1.3, weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.register_buffer(\"class_weight\", weight if weight is not None else None)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce = nn.functional.cross_entropy(logits, targets, weight=self.class_weight, reduction=\"none\")\n",
    "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "        pt = probabilities.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        loss = ((1.0 - pt) ** self.gamma) * ce\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04009493",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68638c5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:18:28.348021Z",
     "iopub.status.busy": "2025-10-03T15:18:28.347445Z",
     "iopub.status.idle": "2025-10-03T15:23:00.037497Z",
     "shell.execute_reply": "2025-10-03T15:23:00.034668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01 | train loss 0.2506 acc 0.7332 bal_acc 0.7602 f1 0.7076 | val loss 0.3192 acc 0.6910 bal_acc 0.7166 f1 0.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 02 | train loss 0.2015 acc 0.7701 bal_acc 0.7977 f1 0.7465 | val loss 0.3043 acc 0.7101 bal_acc 0.7329 f1 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 03 | train loss 0.1856 acc 0.7841 bal_acc 0.8115 f1 0.7609 | val loss 0.3279 acc 0.7503 bal_acc 0.7190 f1 0.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 04 | train loss 0.1752 acc 0.7911 bal_acc 0.8188 f1 0.7687 | val loss 0.3338 acc 0.7207 bal_acc 0.7215 f1 0.6677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 05 | train loss 0.1683 acc 0.7951 bal_acc 0.8231 f1 0.7729 | val loss 0.3419 acc 0.6919 bal_acc 0.7242 f1 0.6566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 06 | train loss 0.1643 acc 0.7978 bal_acc 0.8261 f1 0.7758 | val loss 0.3623 acc 0.6902 bal_acc 0.7047 f1 0.6398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 07 | train loss 0.1549 acc 0.8062 bal_acc 0.8345 f1 0.7847 | val loss 0.3482 acc 0.6962 bal_acc 0.7266 f1 0.6468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SleepMLP(\n",
       "  (stem): Sequential(\n",
       "    (0): Linear(in_features=59, out_features=384, bias=True)\n",
       "    (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-3): 4 x ResidualBlock(\n",
       "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=384, out_features=537, bias=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "      (fc2): Linear(in_features=537, out_features=384, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=384, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weights = torch.tensor([weight_lookup[idx] for idx in range(len(STAGES))], dtype=torch.float32)\n",
    "loss_weights = loss_weights / loss_weights.mean()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SleepMLP(len(FEATURES), 384, 4, 1.4, 0.2, len(STAGES)).to(device)\n",
    "criterion = FocalLoss(gamma=1.15, weight=loss_weights.to(device))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=5e-4)\n",
    "epochs = 20\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1.5e-3, epochs=epochs, steps_per_epoch=steps_per_epoch, pct_start=0.35, div_factor=10.0, final_div_factor=30.0)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
    "\n",
    "def run_epoch(model, loader, criterion, device, optimizer=None, scaler=None, scheduler=None, grad_clip=None):\n",
    "    is_train = optimizer is not None\n",
    "    model.train() if is_train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    autocast_enabled = scaler is not None and scaler.is_enabled()\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for features, targets in loader:\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast(enabled=autocast_enabled):\n",
    "                logits = model(features)\n",
    "                loss = criterion(logits, targets)\n",
    "            if is_train:\n",
    "                if scaler is not None and scaler.is_enabled():\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    if grad_clip is not None:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    if grad_clip is not None:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                    optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "            total_loss += loss.item() * features.size(0)\n",
    "            total_samples += features.size(0)\n",
    "            predictions = logits.detach().argmax(dim=1)\n",
    "            total_correct += (predictions == targets).sum().item()\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "            all_predictions.append(predictions.cpu())\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "    epoch_loss = total_loss / max(total_samples, 1)\n",
    "    epoch_acc = total_correct / max(total_samples, 1)\n",
    "    targets_array = torch.cat(all_targets).numpy()\n",
    "    predictions_array = torch.cat(all_predictions).numpy()\n",
    "    logits_array = torch.cat(all_logits).numpy()\n",
    "    return epoch_loss, epoch_acc, targets_array, predictions_array, logits_array\n",
    "\n",
    "history = []\n",
    "best_state = None\n",
    "best_metric = -np.inf\n",
    "patience = 4\n",
    "wait = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc, train_targets, train_preds, train_logits = run_epoch(model, train_loader, criterion, device, optimizer, scaler, scheduler, grad_clip=1.0)\n",
    "    train_balanced_acc = balanced_accuracy_score(train_targets, train_preds)\n",
    "    train_macro_f1 = f1_score(train_targets, train_preds, average=\"macro\")\n",
    "    val_loss, val_acc, val_targets, val_preds, val_logits = run_epoch(model, val_loader, criterion, device)\n",
    "    val_balanced_acc = balanced_accuracy_score(val_targets, val_preds)\n",
    "    val_macro_f1 = f1_score(val_targets, val_preds, average=\"macro\")\n",
    "    history.append({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_balanced_acc\": train_balanced_acc,\n",
    "        \"train_macro_f1\": train_macro_f1,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_balanced_acc\": val_balanced_acc,\n",
    "        \"val_macro_f1\": val_macro_f1\n",
    "    })\n",
    "    print(f\"epoch {epoch:02d} | train loss {train_loss:.4f} acc {train_acc:.4f} bal_acc {train_balanced_acc:.4f} f1 {train_macro_f1:.4f} | val loss {val_loss:.4f} acc {val_acc:.4f} bal_acc {val_balanced_acc:.4f} f1 {val_macro_f1:.4f}\")\n",
    "    if val_macro_f1 > best_metric:\n",
    "        best_metric = val_macro_f1\n",
    "        best_state = {key: value.cpu() for key, value in model.state_dict().items()}\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ced5bb",
   "metadata": {},
   "source": [
    "## Historico de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "899bb8c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:23:00.048870Z",
     "iopub.status.busy": "2025-10-03T15:23:00.047232Z",
     "iopub.status.idle": "2025-10-03T15:23:00.102792Z",
     "shell.execute_reply": "2025-10-03T15:23:00.099237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_balanced_acc</th>\n",
       "      <th>train_macro_f1</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_balanced_acc</th>\n",
       "      <th>val_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250568</td>\n",
       "      <td>0.733222</td>\n",
       "      <td>0.760248</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.319157</td>\n",
       "      <td>0.691017</td>\n",
       "      <td>0.716554</td>\n",
       "      <td>0.643065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.201530</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>0.797681</td>\n",
       "      <td>0.746460</td>\n",
       "      <td>0.304324</td>\n",
       "      <td>0.710130</td>\n",
       "      <td>0.732880</td>\n",
       "      <td>0.657914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.185633</td>\n",
       "      <td>0.784103</td>\n",
       "      <td>0.811519</td>\n",
       "      <td>0.760885</td>\n",
       "      <td>0.327886</td>\n",
       "      <td>0.750313</td>\n",
       "      <td>0.718990</td>\n",
       "      <td>0.679277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.175196</td>\n",
       "      <td>0.791110</td>\n",
       "      <td>0.818790</td>\n",
       "      <td>0.768702</td>\n",
       "      <td>0.333819</td>\n",
       "      <td>0.720653</td>\n",
       "      <td>0.721538</td>\n",
       "      <td>0.667697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.795136</td>\n",
       "      <td>0.823143</td>\n",
       "      <td>0.772944</td>\n",
       "      <td>0.341932</td>\n",
       "      <td>0.691867</td>\n",
       "      <td>0.724167</td>\n",
       "      <td>0.656607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.164329</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>0.826071</td>\n",
       "      <td>0.775780</td>\n",
       "      <td>0.362266</td>\n",
       "      <td>0.690239</td>\n",
       "      <td>0.704701</td>\n",
       "      <td>0.639781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.154860</td>\n",
       "      <td>0.806205</td>\n",
       "      <td>0.834469</td>\n",
       "      <td>0.784663</td>\n",
       "      <td>0.348228</td>\n",
       "      <td>0.696208</td>\n",
       "      <td>0.726612</td>\n",
       "      <td>0.646822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  train_acc  train_balanced_acc  train_macro_f1  val_loss  \\\n",
       "0      1    0.250568   0.733222            0.760248        0.707642  0.319157   \n",
       "1      2    0.201530   0.770090            0.797681        0.746460  0.304324   \n",
       "2      3    0.185633   0.784103            0.811519        0.760885  0.327886   \n",
       "3      4    0.175196   0.791110            0.818790        0.768702  0.333819   \n",
       "4      5    0.168300   0.795136            0.823143        0.772944  0.341932   \n",
       "5      6    0.164329   0.797841            0.826071        0.775780  0.362266   \n",
       "6      7    0.154860   0.806205            0.834469        0.784663  0.348228   \n",
       "\n",
       "    val_acc  val_balanced_acc  val_macro_f1  \n",
       "0  0.691017          0.716554      0.643065  \n",
       "1  0.710130          0.732880      0.657914  \n",
       "2  0.750313          0.718990      0.679277  \n",
       "3  0.720653          0.721538      0.667697  \n",
       "4  0.691867          0.724167      0.656607  \n",
       "5  0.690239          0.704701      0.639781  \n",
       "6  0.696208          0.726612      0.646822  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf440b56",
   "metadata": {},
   "source": [
    "## Avaliacao no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a750188a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:23:00.109945Z",
     "iopub.status.busy": "2025-10-03T15:23:00.109509Z",
     "iopub.status.idle": "2025-10-03T15:23:04.679611Z",
     "shell.execute_reply": "2025-10-03T15:23:04.677724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123331/3988113616.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=autocast_enabled):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           metric    value\n",
      "             loss 0.694315\n",
      "         accuracy 0.731841\n",
      "balanced_accuracy 0.729671\n",
      "         macro_f1 0.678694\n",
      "\n",
      "              precision  recall  f1-score  support\n",
      "W                 0.910   0.886     0.898  11429.0\n",
      "N1                0.307   0.545     0.393   3425.0\n",
      "N2                0.891   0.634     0.741  13722.0\n",
      "N3                0.544   0.857     0.666   1983.0\n",
      "REM               0.669   0.727     0.697   5319.0\n",
      "macro avg         0.664   0.730     0.679  35878.0\n",
      "weighted avg      0.789   0.732     0.747  35878.0\n",
      "\n",
      "         W    N1    N2    N3   REM\n",
      "W    10128   880    75    19   327\n",
      "N1     591  1866   316    35   617\n",
      "N2      71  2646  8699  1336   970\n",
      "N3       0    54   230  1699     0\n",
      "REM    340   635   447    32  3865\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_targets, test_preds, test_logits = run_epoch(model, test_loader, criterion, device)\n",
    "test_probabilities = torch.softmax(torch.from_numpy(test_logits), dim=1).numpy()\n",
    "test_logloss = log_loss(test_targets, test_probabilities)\n",
    "test_balanced_acc = balanced_accuracy_score(test_targets, test_preds)\n",
    "test_macro_f1 = f1_score(test_targets, test_preds, average=\"macro\")\n",
    "test_accuracy = accuracy_score(test_targets, test_preds)\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"loss\", \"accuracy\", \"balanced_accuracy\", \"macro_f1\"],\n",
    "    \"value\": [test_logloss, test_accuracy, test_balanced_acc, test_macro_f1]\n",
    "})\n",
    "print(summary.to_string(index=False))\n",
    "print()\n",
    "report = classification_report(test_targets, test_preds, target_names=STAGES, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_table = report_df.loc[STAGES + [\"macro avg\", \"weighted avg\"], [\"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
    "print(report_table.round(3).to_string())\n",
    "print()\n",
    "confusion = confusion_matrix(test_targets, test_preds)\n",
    "confusion_df = pd.DataFrame(confusion, index=STAGES, columns=STAGES)\n",
    "print(confusion_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
