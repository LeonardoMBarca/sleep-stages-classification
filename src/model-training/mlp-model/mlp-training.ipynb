{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7447e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, json, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, balanced_accuracy_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4444a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path().resolve().parents[2]\n",
    "DATASETS_PATH = BASE_PATH / \"datalake\" / \"data-for-model\"\n",
    "TRAINING_DATA_FILE = DATASETS_PATH / \"train\" / \"train_sleep_cassette.parquet\" \n",
    "VALIDATION_DATA_FILE = DATASETS_PATH / \"val\" / \"val_sleep_cassette.parquet\" \n",
    "TEST_DATA_FILE = DATASETS_PATH / \"test\" / \"test_sleep_cassette.parquet\" \n",
    "\n",
    "STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "STAGE2ID = {s:i for i, s in enumerate(STAGES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6842441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(TRAINING_DATA_FILE, engine=\"fastparquet\")\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_FILE, engine=\"fastparquet\")\n",
    "df_test = pd.read_parquet(TEST_DATA_FILE, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14195e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_404916/2621182497.py:217: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_amp = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/40] train_loss=0.6255 val_macroF1=0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/40] train_loss=0.4357 val_macroF1=0.6082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/40] train_loss=0.3972 val_macroF1=0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/40] train_loss=0.3706 val_macroF1=0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/40] train_loss=0.3612 val_macroF1=0.6098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/40] train_loss=0.3520 val_macroF1=0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/40] train_loss=0.3367 val_macroF1=0.6139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/40] train_loss=0.3284 val_macroF1=0.6305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/40] train_loss=0.3143 val_macroF1=0.6283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/40] train_loss=0.3118 val_macroF1=0.6244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/40] train_loss=0.3057 val_macroF1=0.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/tmp/ipykernel_404916/2621182497.py:229: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/40] train_loss=0.2980 val_macroF1=0.6172\n",
      "Early stopping at epoch 12. Best @ 6 (macro-F1=0.6438)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST macro-F1 = 0.6711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           W     0.9529    0.8166    0.8795     11429\n",
      "          N1     0.2946    0.6301    0.4015      3425\n",
      "          N2     0.8949    0.6043    0.7214     13722\n",
      "          N3     0.4826    0.8926    0.6264      1983\n",
      "         REM     0.6951    0.7612    0.7267      5319\n",
      "\n",
      "    accuracy                         0.7136     35878\n",
      "   macro avg     0.6640    0.7410    0.6711     35878\n",
      "weighted avg     0.8037    0.7136    0.7368     35878\n",
      "\n",
      "Confusion matrix:\n",
      "[[9333 1668   68   19  341]\n",
      " [ 284 2158  341   42  600]\n",
      " [  41 2749 8292 1806  834]\n",
      " [   0   47  165 1770    1]\n",
      " [ 136  703  400   31 4049]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "# =========================\n",
    "# 0) Configs e utilidades\n",
    "# =========================\n",
    "\n",
    "CONFIG = {\n",
    "    \"train_path\": f\"{TRAINING_DATA_FILE}\",  # mude para .csv se for o caso\n",
    "    \"val_path\": f\"{VALIDATION_DATA_FILE}\",\n",
    "    \"test_path\": f\"{TEST_DATA_FILE}\",\n",
    "    # Colunas\n",
    "    \"target_col\": \"stage\",\n",
    "    \"id_cols\": [\"subject_id\", \"night_id\"],  # não entram como features\n",
    "    \"drop_cols\": [\"age\", \"sex\"],            # você disse que não quer usar\n",
    "    # Hiperparâmetros\n",
    "    \"batch_size\": 512,\n",
    "    \"epochs\": 40,\n",
    "    \"patience\": 6,                  # early stopping (macro-F1)\n",
    "    \"lr\": 2e-3,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"hidden_sizes\": [256, 256, 128],\n",
    "    \"dropout\": 0.2,\n",
    "    \"use_sampler\": True,            # WeightedRandomSampler no treino\n",
    "    \"use_class_weight\": True,       # pesos na loss\n",
    "    \"num_workers\": 2,\n",
    "    \"seed\": 42,\n",
    "    \"save_dir\": \"artifacts\",\n",
    "}\n",
    "\n",
    "CLASSES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "CLASS_TO_IDX = {c: i for i, c in enumerate(CLASSES)}\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def load_table(path: str) -> pd.DataFrame:\n",
    "    ext = Path(path).suffix.lower()\n",
    "    if ext == \".parquet\":\n",
    "        return pd.read_parquet(path)\n",
    "    elif ext == \".csv\":\n",
    "        return pd.read_csv(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "# ==================================================\n",
    "# 1) Dataset e normalização (fit no treino apenas)\n",
    "# ==================================================\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, feature_cols: List[str], target_col: str):\n",
    "        self.X = df[feature_cols].to_numpy(dtype=np.float32)\n",
    "        self.y = df[target_col].map(CLASS_TO_IDX).to_numpy(dtype=np.int64)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def prepare_data(cfg: Dict) -> Tuple[TabularDataset, TabularDataset, TabularDataset, List[str], StandardScaler, np.ndarray]:\n",
    "    # Carrega\n",
    "    train_df = load_table(cfg[\"train_path\"])\n",
    "    val_df   = load_table(cfg[\"val_path\"])\n",
    "    test_df  = load_table(cfg[\"test_path\"])\n",
    "\n",
    "    # Sanity: remove duplicadas de nomes que você listou (ocorreu no prompt)\n",
    "    train_df = train_df.loc[:, ~train_df.columns.duplicated()]\n",
    "    val_df   = val_df.loc[:, ~val_df.columns.duplicated()]\n",
    "    test_df  = test_df.loc[:, ~test_df.columns.duplicated()]\n",
    "\n",
    "    # Remove colunas que não vão nas features\n",
    "    cols_to_drop = set(cfg[\"drop_cols\"] + [cfg[\"target_col\"]] + cfg[\"id_cols\"])\n",
    "    all_cols = [c for c in train_df.columns if c not in cols_to_drop]\n",
    "\n",
    "    # Garante que as colunas de features existem nas três partições\n",
    "    feature_cols = [c for c in all_cols if c in val_df.columns and c in test_df.columns]\n",
    "\n",
    "    # Checagem de nulos (você disse que não há, mas assert explícito ajuda)\n",
    "    assert not train_df[feature_cols + [cfg[\"target_col\"]]].isnull().any().any()\n",
    "    assert not val_df[feature_cols + [cfg[\"target_col\"]]].isnull().any().any()\n",
    "    assert not test_df[feature_cols + [cfg[\"target_col\"]]].isnull().any().any()\n",
    "\n",
    "    # Escalador: fit no treino, transform nos demais\n",
    "    scaler = StandardScaler()\n",
    "    train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols].to_numpy(dtype=np.float32))\n",
    "    val_df[feature_cols]   = scaler.transform(val_df[feature_cols].to_numpy(dtype=np.float32))\n",
    "    test_df[feature_cols]  = scaler.transform(test_df[feature_cols].to_numpy(dtype=np.float32))\n",
    "\n",
    "    # Datasets\n",
    "    ds_train = TabularDataset(train_df, feature_cols, cfg[\"target_col\"])\n",
    "    ds_val   = TabularDataset(val_df, feature_cols, cfg[\"target_col\"])\n",
    "    ds_test  = TabularDataset(test_df, feature_cols, cfg[\"target_col\"])\n",
    "\n",
    "    # Pesos por classe (frequência do treino)\n",
    "    counts = np.bincount(ds_train.y, minlength=len(CLASSES)).astype(np.float64)\n",
    "    class_weights = (counts.sum() / (counts + 1e-8))  # inverso da frequência\n",
    "    class_weights = class_weights / class_weights.mean()  # normaliza\n",
    "\n",
    "    return ds_train, ds_val, ds_test, feature_cols, scaler, class_weights\n",
    "\n",
    "# ==================================\n",
    "# 2) MLP para tabular (BN + SiLU)\n",
    "# ==================================\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_f, out_f, p_drop=0.2):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(in_f, out_f)\n",
    "        self.bn  = nn.BatchNorm1d(out_f)\n",
    "        self.act = nn.SiLU()\n",
    "        self.do  = nn.Dropout(p_drop)\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x = self.do(x)\n",
    "        return x\n",
    "\n",
    "class TabMLP(nn.Module):\n",
    "    def __init__(self, in_features: int, hidden: List[int], num_classes: int, p_drop: float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_features\n",
    "        for h in hidden:\n",
    "            layers.append(Block(prev, h, p_drop))\n",
    "            prev = h\n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(prev, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return self.head(x)\n",
    "\n",
    "# ======================================\n",
    "# 3) Treino, validação, inferência\n",
    "# ======================================\n",
    "\n",
    "def make_loader(ds: Dataset, cfg: Dict, class_weights: np.ndarray = None, train: bool = False):\n",
    "    if train and cfg[\"use_sampler\"]:\n",
    "        # probabilidade ~ inverso da frequência\n",
    "        sample_weights = class_weights[ds.y]\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=torch.as_tensor(sample_weights, dtype=torch.double),\n",
    "            num_samples=len(ds),\n",
    "            replacement=True\n",
    "        )\n",
    "        return DataLoader(ds, batch_size=cfg[\"batch_size\"], sampler=sampler,\n",
    "                          num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    else:\n",
    "        shuffle = train and not cfg[\"use_sampler\"]\n",
    "        return DataLoader(ds, batch_size=cfg[\"batch_size\"], shuffle=shuffle,\n",
    "                          num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ys, yps = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            logits = model(xb)\n",
    "            y_hat = logits.argmax(1)\n",
    "            ys.append(yb.cpu().numpy())\n",
    "            yps.append(y_hat.cpu().numpy())\n",
    "    y_true = np.concatenate(ys)\n",
    "    y_pred = np.concatenate(yps)\n",
    "    macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return macro, y_true, y_pred\n",
    "\n",
    "def train(cfg: Dict):\n",
    "    os.makedirs(cfg[\"save_dir\"], exist_ok=True)\n",
    "    set_seed(cfg[\"seed\"])\n",
    "\n",
    "    ds_train, ds_val, ds_test, feature_cols, scaler, class_weights = prepare_data(cfg)\n",
    "    input_dim = len(feature_cols)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = TabMLP(\n",
    "        in_features=input_dim,\n",
    "        hidden=cfg[\"hidden_sizes\"],\n",
    "        num_classes=len(CLASSES),\n",
    "        p_drop=cfg[\"dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    # Loss com pesos por classe\n",
    "    if cfg[\"use_class_weight\"]:\n",
    "        weight_t = torch.tensor(class_weights, dtype=torch.float32, device=device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=weight_t)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "\n",
    "    # LRs com OneCycle\n",
    "    steps_per_epoch = math.ceil(len(ds_train) / cfg[\"batch_size\"])\n",
    "    total_steps = steps_per_epoch * cfg[\"epochs\"]\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=cfg[\"lr\"], total_steps=total_steps, pct_start=0.15, div_factor=10.0, final_div_factor=1e3\n",
    "    )\n",
    "\n",
    "    train_loader = make_loader(ds_train, cfg, class_weights, train=True)\n",
    "    val_loader   = make_loader(ds_val, cfg, class_weights, train=False)\n",
    "\n",
    "    scaler_amp = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "    best_f1, best_epoch, wait = -1.0, -1, 0\n",
    "    best_path = Path(cfg[\"save_dir\"]) / \"best_mlp.pt\"\n",
    "\n",
    "    for epoch in range(cfg[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb)\n",
    "            scaler_amp.scale(loss).backward()\n",
    "            scaler_amp.step(optimizer)\n",
    "            scaler_amp.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(ds_train)\n",
    "        val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        print(f\"[{epoch+1}/{cfg['epochs']}] train_loss={train_loss:.4f} val_macroF1={val_f1:.4f}\")\n",
    "\n",
    "        # early stopping por macro-F1\n",
    "        if val_f1 > best_f1 + 1e-5:\n",
    "            best_f1, best_epoch, wait = val_f1, epoch, 0\n",
    "            torch.save({\"model\": model.state_dict(),\n",
    "                        \"feature_cols\": feature_cols,\n",
    "                        \"scaler_mean\": scaler.mean_.tolist(),\n",
    "                        \"scaler_scale\": scaler.scale_.tolist()}, best_path)\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= cfg[\"patience\"]:\n",
    "                print(f\"Early stopping at epoch {epoch+1}. Best @ {best_epoch+1} (macro-F1={best_f1:.4f})\")\n",
    "                break\n",
    "\n",
    "    # Carrega melhor e avalia no teste\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    # reconstroi scaler (para export)\n",
    "    saved_scaler = StandardScaler()\n",
    "    saved_scaler.mean_ = np.array(ckpt[\"scaler_mean\"])\n",
    "    saved_scaler.scale_ = np.array(ckpt[\"scaler_scale\"])\n",
    "    saved_scaler.var_ = saved_scaler.scale_ ** 2\n",
    "\n",
    "    test_loader = make_loader(ds_test, CONFIG, train=False)\n",
    "    test_f1, y_true, y_pred = evaluate(model, test_loader, device)\n",
    "    print(f\"TEST macro-F1 = {test_f1:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    # Salva relatório\n",
    "    with open(Path(cfg[\"save_dir\"]) / \"test_report.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"macro_f1\": float(test_f1),\n",
    "            \"report\": classification_report(y_true, y_pred, target_names=CLASSES, digits=4, output_dict=True),\n",
    "            \"confusion_matrix\": confusion_matrix(y_true, y_pred).tolist()\n",
    "        }, f, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(CONFIG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
