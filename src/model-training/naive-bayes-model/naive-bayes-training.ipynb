{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7931472",
   "metadata": {},
   "source": [
    "# Classificacao dos estagios do sono com Naive Bayes\n",
    "\n",
    "Este notebook organiza o pipeline de treino, validacao e teste para o modelo aplicado aos dados de estagios do sono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e608c7be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:27.645968Z",
     "iopub.status.busy": "2025-10-03T02:08:27.645117Z",
     "iopub.status.idle": "2025-10-03T02:08:20.910947Z",
     "shell.execute_reply": "2025-10-03T02:08:20.906913Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a922b",
   "metadata": {},
   "source": [
    "## Configuracao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d1633ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:20.916904Z",
     "iopub.status.busy": "2025-10-03T02:08:20.915811Z",
     "iopub.status.idle": "2025-10-03T02:08:32.846251Z",
     "shell.execute_reply": "2025-10-03T02:08:32.839820Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = Path().resolve()\n",
    "if not (BASE_PATH / \"datalake\").exists():\n",
    "    BASE_PATH = BASE_PATH.parents[2]\n",
    "DATASETS_PATH = BASE_PATH / \"datalake\" / \"data-for-model\"\n",
    "TRAINING_DATA_FILE = DATASETS_PATH / \"train\" / \"train_sleep_cassette.parquet\"\n",
    "VALIDATION_DATA_FILE = DATASETS_PATH / \"val\" / \"val_sleep_cassette.parquet\"\n",
    "TEST_DATA_FILE = DATASETS_PATH / \"test\" / \"test_sleep_cassette.parquet\"\n",
    "STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "STAGE2ID = {stage: idx for idx, stage in enumerate(STAGES)}\n",
    "df_train = pd.read_parquet(TRAINING_DATA_FILE, engine=\"fastparquet\")\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_FILE, engine=\"fastparquet\")\n",
    "df_test = pd.read_parquet(TEST_DATA_FILE, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78658bf",
   "metadata": {},
   "source": [
    "## Preparacao das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ffef64c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:32.861951Z",
     "iopub.status.busy": "2025-10-03T02:08:32.860773Z",
     "iopub.status.idle": "2025-10-03T02:08:22.742232Z",
     "shell.execute_reply": "2025-10-03T02:08:22.740269Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "SEX_MAP = {\"F\": 0.0, \"M\": 1.0}\n",
    "frames = [df_train, df_val, df_test]\n",
    "for frame in frames:\n",
    "    frame[\"sex\"] = frame[\"sex\"].map(SEX_MAP).fillna(0.5).astype(np.float32)\n",
    "    frame[\"stage_id\"] = frame[\"stage\"].map(STAGE2ID).astype(np.int64)\n",
    "\n",
    "IDENTIFIERS = [\"subject_id\", \"night_id\", \"epoch_idx\", \"stage\", \"stage_id\"]\n",
    "FEATURES = [column for column in df_train.columns if column not in IDENTIFIERS]\n",
    "FEATURES.sort()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(df_train[FEATURES]).astype(np.float32)\n",
    "x_val = scaler.transform(df_val[FEATURES]).astype(np.float32)\n",
    "x_test = scaler.transform(df_test[FEATURES]).astype(np.float32)\n",
    "\n",
    "y_train = df_train[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_val = df_val[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_test = df_test[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "class_distribution = df_train[\"stage_id\"].value_counts().sort_index()\n",
    "class_weights = (len(df_train) / (len(STAGES) * class_distribution)).astype(np.float64)\n",
    "weight_lookup = {idx: float(value) for idx, value in class_weights.items()}\n",
    "train_weights = np.array([weight_lookup[label] for label in y_train], dtype=np.float64)\n",
    "val_weights = np.array([weight_lookup[label] for label in y_val], dtype=np.float64)\n",
    "test_weights = np.array([weight_lookup[label] for label in y_test], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b3f7d",
   "metadata": {},
   "source": [
    "## Distribuicao das classes no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4ab230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:22.753270Z",
     "iopub.status.busy": "2025-10-03T02:08:22.752642Z",
     "iopub.status.idle": "2025-10-03T02:08:22.825527Z",
     "shell.execute_reply": "2025-10-03T02:08:22.818412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>samples</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>34935</td>\n",
       "      <td>0.309837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>13882</td>\n",
       "      <td>0.123119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2</td>\n",
       "      <td>40344</td>\n",
       "      <td>0.357809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3</td>\n",
       "      <td>8532</td>\n",
       "      <td>0.075670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REM</td>\n",
       "      <td>15060</td>\n",
       "      <td>0.133566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stage  samples  proportion\n",
       "0     W    34935    0.309837\n",
       "1    N1    13882    0.123119\n",
       "2    N2    40344    0.357809\n",
       "3    N3     8532    0.075670\n",
       "4   REM    15060    0.133566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_summary = pd.DataFrame({\n",
    "    \"stage\": STAGES,\n",
    "    \"samples\": [int(class_distribution.get(idx, 0)) for idx in range(len(STAGES))]\n",
    "})\n",
    "class_summary[\"proportion\"] = class_summary[\"samples\"] / class_summary[\"samples\"].sum()\n",
    "class_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768afdc",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3c313b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:22.841224Z",
     "iopub.status.busy": "2025-10-03T02:08:22.840664Z",
     "iopub.status.idle": "2025-10-03T02:08:30.381681Z",
     "shell.execute_reply": "2025-10-03T02:08:30.379030Z"
    }
   },
   "outputs": [],
   "source": [
    "smoothing_grid = np.logspace(-9, -3, 13)\n",
    "history_records = []\n",
    "best_score = -np.inf\n",
    "best_model = None\n",
    "for smoothing in smoothing_grid:\n",
    "    candidate = GaussianNB(var_smoothing=smoothing)\n",
    "    candidate.fit(x_train, y_train, sample_weight=train_weights)\n",
    "    val_predictions = candidate.predict(x_val)\n",
    "    score = f1_score(y_val, val_predictions, average=\"macro\")\n",
    "    history_records.append({\"var_smoothing\": smoothing, \"val_macro_f1\": score})\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = candidate\n",
    "history_df = pd.DataFrame(history_records).sort_values(\"val_macro_f1\", ascending=False).reset_index(drop=True)\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeec5dc",
   "metadata": {},
   "source": [
    "## Historico de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b211fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:30.391300Z",
     "iopub.status.busy": "2025-10-03T02:08:30.387262Z",
     "iopub.status.idle": "2025-10-03T02:08:30.436739Z",
     "shell.execute_reply": "2025-10-03T02:08:30.430586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>val_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.595972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.162278e-06</td>\n",
       "      <td>0.595958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.162278e-05</td>\n",
       "      <td>0.595958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.595958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.162278e-04</td>\n",
       "      <td>0.595953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.162278e-08</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.162278e-09</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.162278e-07</td>\n",
       "      <td>0.595939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>0.595817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_smoothing  val_macro_f1\n",
       "0    1.000000e-04      0.595972\n",
       "1    3.162278e-06      0.595958\n",
       "2    3.162278e-05      0.595958\n",
       "3    1.000000e-05      0.595958\n",
       "4    3.162278e-04      0.595953\n",
       "5    1.000000e-07      0.595939\n",
       "6    3.162278e-08      0.595939\n",
       "7    1.000000e-08      0.595939\n",
       "8    3.162278e-09      0.595939\n",
       "9    1.000000e-09      0.595939\n",
       "10   1.000000e-06      0.595939\n",
       "11   3.162278e-07      0.595939\n",
       "12   1.000000e-03      0.595817"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd7cd0c",
   "metadata": {},
   "source": [
    "## Avaliacao no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820ff0dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T02:08:30.444932Z",
     "iopub.status.busy": "2025-10-03T02:08:30.444497Z",
     "iopub.status.idle": "2025-10-03T02:08:42.761860Z",
     "shell.execute_reply": "2025-10-03T02:08:42.758656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           metric    value\n",
      "             loss 5.524137\n",
      "         accuracy 0.649451\n",
      "balanced_accuracy 0.639431\n",
      "         macro_f1 0.581154\n",
      "\n",
      "              precision  recall  f1-score  support\n",
      "W                 0.925   0.706     0.801  11429.0\n",
      "N1                0.237   0.350     0.282   3425.0\n",
      "N2                0.776   0.664     0.716  13722.0\n",
      "N3                0.387   0.880     0.537   1983.0\n",
      "REM               0.544   0.597     0.569   5319.0\n",
      "macro avg         0.574   0.639     0.581  35878.0\n",
      "weighted avg      0.716   0.649     0.670  35878.0\n",
      "\n",
      "        W    N1    N2    N3   REM\n",
      "W    8073  2076   298    13   969\n",
      "N1    426  1199   929    52   819\n",
      "N2     77  1057  9109  2614   865\n",
      "N3      1     3   230  1745     4\n",
      "REM   150   734  1173    87  3175\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(x_val)\n",
    "test_predictions = model.predict(x_test)\n",
    "test_probabilities = model.predict_proba(x_test)\n",
    "test_loss = log_loss(y_test, test_probabilities)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, test_predictions)\n",
    "test_macro_f1 = f1_score(y_test, test_predictions, average=\"macro\")\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"loss\", \"accuracy\", \"balanced_accuracy\", \"macro_f1\"],\n",
    "    \"value\": [test_loss, test_accuracy, test_balanced_acc, test_macro_f1]\n",
    "})\n",
    "print(summary.to_string(index=False))\n",
    "print()\n",
    "report = classification_report(y_test, test_predictions, target_names=STAGES, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_table = report_df.loc[STAGES + [\"macro avg\", \"weighted avg\"], [\"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
    "print(report_table.round(3).to_string())\n",
    "print()\n",
    "confusion = confusion_matrix(y_test, test_predictions)\n",
    "confusion_df = pd.DataFrame(confusion, index=STAGES, columns=STAGES)\n",
    "print(confusion_df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
