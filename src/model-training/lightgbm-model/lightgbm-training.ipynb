{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92e9c15",
   "metadata": {},
   "source": [
    "# Classificacao dos estagios do sono com LightGBM\n",
    "\n",
    "Este notebook organiza o pipeline de treino, validacao e teste para o modelo aplicado aos dados de estagios do sono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398a7860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:19.660277Z",
     "iopub.status.busy": "2025-10-03T12:03:19.660009Z",
     "iopub.status.idle": "2025-10-03T12:03:21.286843Z",
     "shell.execute_reply": "2025-10-03T12:03:21.286032Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bf554",
   "metadata": {},
   "source": [
    "## Configuracao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3355c989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:21.290177Z",
     "iopub.status.busy": "2025-10-03T12:03:21.289684Z",
     "iopub.status.idle": "2025-10-03T12:03:21.683231Z",
     "shell.execute_reply": "2025-10-03T12:03:21.682201Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = Path().resolve()\n",
    "if not (BASE_PATH / \"datalake\").exists():\n",
    "    BASE_PATH = BASE_PATH.parents[2]\n",
    "DATASETS_PATH = BASE_PATH / \"datalake\" / \"data-for-model\"\n",
    "TRAINING_DATA_FILE = DATASETS_PATH / \"train\" / \"train_sleep_cassette.parquet\"\n",
    "VALIDATION_DATA_FILE = DATASETS_PATH / \"val\" / \"val_sleep_cassette.parquet\"\n",
    "TEST_DATA_FILE = DATASETS_PATH / \"test\" / \"test_sleep_cassette.parquet\"\n",
    "STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "STAGE2ID = {stage: idx for idx, stage in enumerate(STAGES)}\n",
    "df_train = pd.read_parquet(TRAINING_DATA_FILE, engine=\"fastparquet\")\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_FILE, engine=\"fastparquet\")\n",
    "df_test = pd.read_parquet(TEST_DATA_FILE, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e2544e",
   "metadata": {},
   "source": [
    "## Preparacao das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da66208",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:21.685815Z",
     "iopub.status.busy": "2025-10-03T12:03:21.685424Z",
     "iopub.status.idle": "2025-10-03T12:03:22.070159Z",
     "shell.execute_reply": "2025-10-03T12:03:22.069421Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "SEX_MAP = {\"F\": 0.0, \"M\": 1.0}\n",
    "frames = [df_train, df_val, df_test]\n",
    "for frame in frames:\n",
    "    frame[\"sex\"] = frame[\"sex\"].map(SEX_MAP).fillna(0.5).astype(np.float32)\n",
    "    frame[\"stage_id\"] = frame[\"stage\"].map(STAGE2ID).astype(np.int64)\n",
    "\n",
    "IDENTIFIERS = [\"subject_id\", \"night_id\", \"epoch_idx\", \"stage\", \"stage_id\"]\n",
    "FEATURES = [column for column in df_train.columns if column not in IDENTIFIERS]\n",
    "FEATURES.sort()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(df_train[FEATURES]).astype(np.float32)\n",
    "x_val = scaler.transform(df_val[FEATURES]).astype(np.float32)\n",
    "x_test = scaler.transform(df_test[FEATURES]).astype(np.float32)\n",
    "\n",
    "y_train = df_train[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_val = df_val[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_test = df_test[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "class_distribution = df_train[\"stage_id\"].value_counts().sort_index()\n",
    "class_weights = (len(df_train) / (len(STAGES) * class_distribution)).astype(np.float64)\n",
    "weight_lookup = {idx: float(value) for idx, value in class_weights.items()}\n",
    "train_weights = np.array([weight_lookup[label] for label in y_train], dtype=np.float64)\n",
    "val_weights = np.array([weight_lookup[label] for label in y_val], dtype=np.float64)\n",
    "test_weights = np.array([weight_lookup[label] for label in y_test], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fdda8",
   "metadata": {},
   "source": [
    "## Distribuicao das classes no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2a6e31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:22.073884Z",
     "iopub.status.busy": "2025-10-03T12:03:22.073424Z",
     "iopub.status.idle": "2025-10-03T12:03:22.086035Z",
     "shell.execute_reply": "2025-10-03T12:03:22.085174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>samples</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>34935</td>\n",
       "      <td>0.309837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>13882</td>\n",
       "      <td>0.123119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2</td>\n",
       "      <td>40344</td>\n",
       "      <td>0.357809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3</td>\n",
       "      <td>8532</td>\n",
       "      <td>0.075670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REM</td>\n",
       "      <td>15060</td>\n",
       "      <td>0.133566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stage  samples  proportion\n",
       "0     W    34935    0.309837\n",
       "1    N1    13882    0.123119\n",
       "2    N2    40344    0.357809\n",
       "3    N3     8532    0.075670\n",
       "4   REM    15060    0.133566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_summary = pd.DataFrame({\n",
    "    \"stage\": STAGES,\n",
    "    \"samples\": [int(class_distribution.get(idx, 0)) for idx in range(len(STAGES))]\n",
    "})\n",
    "class_summary[\"proportion\"] = class_summary[\"samples\"] / class_summary[\"samples\"].sum()\n",
    "class_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82921e1c",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f410eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:22.089751Z",
     "iopub.status.busy": "2025-10-03T12:03:22.089289Z",
     "iopub.status.idle": "2025-10-03T12:03:52.889608Z",
     "shell.execute_reply": "2025-10-03T12:03:52.887418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14206\n",
      "[LightGBM] [Info] Number of data points in the train set: 112753, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\ttreino's multi_logloss: 0.599177\ttreino's multi_error: 0.141129\tvalidacao's multi_logloss: 0.800536\tvalidacao's multi_error: 0.259514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttreino's multi_logloss: 0.390096\ttreino's multi_error: 0.114391\tvalidacao's multi_logloss: 0.695251\tvalidacao's multi_error: 0.25709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75]\ttreino's multi_logloss: 0.302143\ttreino's multi_error: 0.0932015\tvalidacao's multi_logloss: 0.680949\tvalidacao's multi_error: 0.255268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttreino's multi_logloss: 0.249784\ttreino's multi_error: 0.0749293\tvalidacao's multi_logloss: 0.685161\tvalidacao's multi_error: 0.255401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125]\ttreino's multi_logloss: 0.213439\ttreino's multi_error: 0.0609763\tvalidacao's multi_logloss: 0.694143\tvalidacao's multi_error: 0.255148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttreino's multi_logloss: 0.185476\ttreino's multi_error: 0.0490326\tvalidacao's multi_logloss: 0.703847\tvalidacao's multi_error: 0.254687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]\ttreino's multi_logloss: 0.163213\ttreino's multi_error: 0.0398192\tvalidacao's multi_logloss: 0.716106\tvalidacao's multi_error: 0.255802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttreino's multi_logloss: 0.144608\ttreino's multi_error: 0.0323148\tvalidacao's multi_logloss: 0.726234\tvalidacao's multi_error: 0.25605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\ttreino's multi_logloss: 0.304561\ttreino's multi_error: 0.0935577\tvalidacao's multi_logloss: 0.680854\tvalidacao's multi_error: 0.255676\n"
     ]
    }
   ],
   "source": [
    "train_weights_array = train_weights\n",
    "val_weights_array = val_weights\n",
    "model = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(STAGES),\n",
    "    n_estimators=2200,\n",
    "    learning_rate=0.045,\n",
    "    num_leaves=104,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=60,\n",
    "    subsample=0.85,\n",
    "    subsample_freq=1,\n",
    "    colsample_bytree=0.7,\n",
    "    reg_lambda=0.9,\n",
    "    reg_alpha=0.02,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1)\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sample_weight=train_weights_array,\n",
    "    eval_set=[(x_train, y_train), (x_val, y_val)],\n",
    "    eval_sample_weight=[train_weights_array, val_weights_array],\n",
    "    eval_metric=[\"multi_logloss\", \"multi_error\"],\n",
    "    eval_names=[\"treino\", \"validacao\"],\n",
    "    callbacks=[early_stopping(stopping_rounds=150), log_evaluation(period=25)]\n",
    ")\n",
    "best_iteration = model.best_iteration_ if model.best_iteration_ is not None else model.n_estimators_\n",
    "history = model.evals_result_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c551c24",
   "metadata": {},
   "source": [
    "## Historico de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e241ce8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:52.895609Z",
     "iopub.status.busy": "2025-10-03T12:03:52.895122Z",
     "iopub.status.idle": "2025-10-03T12:03:52.915050Z",
     "shell.execute_reply": "2025-10-03T12:03:52.914186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>train_logloss</th>\n",
       "      <th>val_logloss</th>\n",
       "      <th>train_error</th>\n",
       "      <th>val_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.504859</td>\n",
       "      <td>1.522432</td>\n",
       "      <td>0.206981</td>\n",
       "      <td>0.314419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.414307</td>\n",
       "      <td>1.444211</td>\n",
       "      <td>0.188396</td>\n",
       "      <td>0.285980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.333748</td>\n",
       "      <td>1.375025</td>\n",
       "      <td>0.178288</td>\n",
       "      <td>0.275402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.262581</td>\n",
       "      <td>1.316039</td>\n",
       "      <td>0.172792</td>\n",
       "      <td>0.272511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.198693</td>\n",
       "      <td>1.264842</td>\n",
       "      <td>0.169627</td>\n",
       "      <td>0.274180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>220</td>\n",
       "      <td>0.132065</td>\n",
       "      <td>0.735298</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>0.257398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>221</td>\n",
       "      <td>0.131457</td>\n",
       "      <td>0.736157</td>\n",
       "      <td>0.027021</td>\n",
       "      <td>0.257618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>222</td>\n",
       "      <td>0.130872</td>\n",
       "      <td>0.736185</td>\n",
       "      <td>0.026776</td>\n",
       "      <td>0.257377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>223</td>\n",
       "      <td>0.130322</td>\n",
       "      <td>0.736663</td>\n",
       "      <td>0.026540</td>\n",
       "      <td>0.257518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>224</td>\n",
       "      <td>0.129786</td>\n",
       "      <td>0.737329</td>\n",
       "      <td>0.026353</td>\n",
       "      <td>0.257606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iteration  train_logloss  val_logloss  train_error  val_error\n",
       "0            1       1.504859     1.522432     0.206981   0.314419\n",
       "1            2       1.414307     1.444211     0.188396   0.285980\n",
       "2            3       1.333748     1.375025     0.178288   0.275402\n",
       "3            4       1.262581     1.316039     0.172792   0.272511\n",
       "4            5       1.198693     1.264842     0.169627   0.274180\n",
       "..         ...            ...          ...          ...        ...\n",
       "219        220       0.132065     0.735298     0.027264   0.257398\n",
       "220        221       0.131457     0.736157     0.027021   0.257618\n",
       "221        222       0.130872     0.736185     0.026776   0.257377\n",
       "222        223       0.130322     0.736663     0.026540   0.257518\n",
       "223        224       0.129786     0.737329     0.026353   0.257606\n",
       "\n",
       "[224 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations = len(history[\"treino\"][\"multi_logloss\"])\n",
    "history_df = pd.DataFrame({\n",
    "    \"iteration\": np.arange(1, iterations + 1),\n",
    "    \"train_logloss\": history[\"treino\"][\"multi_logloss\"],\n",
    "    \"val_logloss\": history[\"validacao\"][\"multi_logloss\"],\n",
    "    \"train_error\": history[\"treino\"].get(\"multi_error\", [np.nan] * iterations),\n",
    "    \"val_error\": history[\"validacao\"].get(\"multi_error\", [np.nan] * iterations)\n",
    "})\n",
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb15484c",
   "metadata": {},
   "source": [
    "## Avaliacao no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee2b710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:52.918196Z",
     "iopub.status.busy": "2025-10-03T12:03:52.917857Z",
     "iopub.status.idle": "2025-10-03T12:04:05.540258Z",
     "shell.execute_reply": "2025-10-03T12:04:05.538278Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/miniconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           metric    value\n",
      "             loss 0.612711\n",
      "         accuracy 0.766375\n",
      "balanced_accuracy 0.725628\n",
      "         macro_f1 0.705784\n",
      "\n",
      "              precision  recall  f1-score  support\n",
      "W                 0.911   0.859     0.884  11429.0\n",
      "N1                0.346   0.469     0.398   3425.0\n",
      "N2                0.860   0.782     0.819  13722.0\n",
      "N3                0.687   0.818     0.747   1983.0\n",
      "REM               0.663   0.701     0.681   5319.0\n",
      "macro avg         0.693   0.726     0.706  35878.0\n",
      "weighted avg      0.788   0.766     0.775  35878.0\n",
      "\n",
      "        W    N1     N2    N3   REM\n",
      "W    9818  1052    125     8   426\n",
      "N1    469  1605    624    14   713\n",
      "N2    114  1421  10724   707   756\n",
      "N3      3    16    341  1623     0\n",
      "REM   377   541    663    12  3726\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(x_val, num_iteration=best_iteration)\n",
    "test_predictions = model.predict(x_test, num_iteration=best_iteration)\n",
    "test_probabilities = model.predict_proba(x_test, num_iteration=best_iteration)\n",
    "test_loss = log_loss(y_test, test_probabilities)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, test_predictions)\n",
    "test_macro_f1 = f1_score(y_test, test_predictions, average=\"macro\")\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"loss\", \"accuracy\", \"balanced_accuracy\", \"macro_f1\"],\n",
    "    \"value\": [test_loss, test_accuracy, test_balanced_acc, test_macro_f1]\n",
    "})\n",
    "print(summary.to_string(index=False))\n",
    "print()\n",
    "report = classification_report(y_test, test_predictions, target_names=STAGES, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_table = report_df.loc[STAGES + [\"macro avg\", \"weighted avg\"], [\"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
    "print(report_table.round(3).to_string())\n",
    "print()\n",
    "confusion = confusion_matrix(y_test, test_predictions)\n",
    "confusion_df = pd.DataFrame(confusion, index=STAGES, columns=STAGES)\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7938217",
   "metadata": {},
   "source": [
    "## Analise adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3105af5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:04:05.543679Z",
     "iopub.status.busy": "2025-10-03T12:04:05.543369Z",
     "iopub.status.idle": "2025-10-03T12:04:05.559087Z",
     "shell.execute_reply": "2025-10-03T12:04:05.558287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tso_min</th>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_p90_1hz_roll_max_10</th>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG_theta_relpow_256_roll_mean_5</th>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_aperiodic_slope_256_roll_mean_15</th>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_theta_relpow_256_roll_mean_5</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_median_1hz</th>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_delta_relpow_256_roll_mean_15</th>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_median_1hz_roll_mean_5</th>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_aperiodic_slope_256</th>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_beta_relpow_256_roll_std_10</th>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_alpha_relpow_256_roll_std_10</th>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG_rms</th>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_spec_entropy_256_roll_mean_15</th>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG_rms_roll_std_10</th>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG_rms_roll_mean_10</th>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_theta_alpha_ratio_256_roll_mean_5</th>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_beta_relpow_256</th>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EOG_rms_roll_mean_5</th>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_spec_entropy_256</th>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              importance\n",
       "age                                                 2202\n",
       "tso_min                                             2072\n",
       "EMG_submental_p90_1hz_roll_max_10                   1257\n",
       "EOG_theta_relpow_256_roll_mean_5                    1157\n",
       "EEG_Fpz_Cz_aperiodic_slope_256_roll_mean_15         1127\n",
       "EEG_Fpz_Cz_theta_relpow_256_roll_mean_5             1000\n",
       "EMG_submental_median_1hz                             889\n",
       "EEG_Pz_Oz_delta_relpow_256_roll_mean_15              852\n",
       "EMG_submental_median_1hz_roll_mean_5                 833\n",
       "EEG_Pz_Oz_aperiodic_slope_256                        820\n",
       "EEG_Pz_Oz_beta_relpow_256_roll_std_10                808\n",
       "EEG_Pz_Oz_alpha_relpow_256_roll_std_10               788\n",
       "EOG_rms                                              778\n",
       "EEG_Pz_Oz_spec_entropy_256_roll_mean_15              776\n",
       "EOG_rms_roll_std_10                                  770\n",
       "EOG_rms_roll_mean_10                                 767\n",
       "EEG_Fpz_Cz_theta_alpha_ratio_256_roll_mean_5         766\n",
       "EEG_Fpz_Cz_beta_relpow_256                           727\n",
       "EOG_rms_roll_mean_5                                  721\n",
       "EEG_Fpz_Cz_spec_entropy_256                          720"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.Series(model.feature_importances_, index=FEATURES)\n",
    "top_importances = importances.sort_values(ascending=False).head(20)\n",
    "top_importances.to_frame(name=\"importance\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
