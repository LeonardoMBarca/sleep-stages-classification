{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946be09c",
   "metadata": {},
   "source": [
    "# Classificacao dos estagios do sono com Random Forest\n",
    "\n",
    "Este notebook organiza o pipeline de treino, validacao e teste para o modelo aplicado aos dados de estagios do sono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45949948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:57:57.316218Z",
     "iopub.status.busy": "2025-10-03T11:57:57.315717Z",
     "iopub.status.idle": "2025-10-03T11:58:20.032609Z",
     "shell.execute_reply": "2025-10-03T11:58:20.031098Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix, f1_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db3cc4",
   "metadata": {},
   "source": [
    "## Configuracao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78edc009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:58:20.070149Z",
     "iopub.status.busy": "2025-10-03T11:58:20.058208Z",
     "iopub.status.idle": "2025-10-03T11:58:24.870517Z",
     "shell.execute_reply": "2025-10-03T11:58:24.869238Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = Path().resolve()\n",
    "if not (BASE_PATH / \"datalake\").exists():\n",
    "    BASE_PATH = BASE_PATH.parents[2]\n",
    "DATASETS_PATH = BASE_PATH / \"datalake\" / \"data-for-model\"\n",
    "TRAINING_DATA_FILE = DATASETS_PATH / \"train\" / \"train_sleep_cassette.parquet\"\n",
    "VALIDATION_DATA_FILE = DATASETS_PATH / \"val\" / \"val_sleep_cassette.parquet\"\n",
    "TEST_DATA_FILE = DATASETS_PATH / \"test\" / \"test_sleep_cassette.parquet\"\n",
    "STAGES = [\"W\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "STAGE2ID = {stage: idx for idx, stage in enumerate(STAGES)}\n",
    "df_train = pd.read_parquet(TRAINING_DATA_FILE, engine=\"fastparquet\")\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_FILE, engine=\"fastparquet\")\n",
    "df_test = pd.read_parquet(TEST_DATA_FILE, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9713ce5",
   "metadata": {},
   "source": [
    "## Preparacao das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d925aa23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:58:24.880065Z",
     "iopub.status.busy": "2025-10-03T11:58:24.878802Z",
     "iopub.status.idle": "2025-10-03T11:58:19.269731Z",
     "shell.execute_reply": "2025-10-03T11:58:19.268323Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "SEX_MAP = {\"F\": 0.0, \"M\": 1.0}\n",
    "frames = [df_train, df_val, df_test]\n",
    "for frame in frames:\n",
    "    frame[\"sex\"] = frame[\"sex\"].map(SEX_MAP).fillna(0.5).astype(np.float32)\n",
    "    frame[\"stage_id\"] = frame[\"stage\"].map(STAGE2ID).astype(np.int64)\n",
    "\n",
    "IDENTIFIERS = [\"subject_id\", \"night_id\", \"epoch_idx\", \"stage\", \"stage_id\"]\n",
    "FEATURES = [column for column in df_train.columns if column not in IDENTIFIERS]\n",
    "FEATURES.sort()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(df_train[FEATURES]).astype(np.float32)\n",
    "x_val = scaler.transform(df_val[FEATURES]).astype(np.float32)\n",
    "x_test = scaler.transform(df_test[FEATURES]).astype(np.float32)\n",
    "\n",
    "y_train = df_train[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_val = df_val[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "y_test = df_test[\"stage_id\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "class_distribution = df_train[\"stage_id\"].value_counts().sort_index()\n",
    "class_weights = (len(df_train) / (len(STAGES) * class_distribution)).astype(np.float64)\n",
    "weight_lookup = {idx: float(value) for idx, value in class_weights.items()}\n",
    "train_weights = np.array([weight_lookup[label] for label in y_train], dtype=np.float64)\n",
    "val_weights = np.array([weight_lookup[label] for label in y_val], dtype=np.float64)\n",
    "test_weights = np.array([weight_lookup[label] for label in y_test], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdcf60d",
   "metadata": {},
   "source": [
    "## Distribuicao das classes no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e246cb9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:58:19.278101Z",
     "iopub.status.busy": "2025-10-03T11:58:19.277597Z",
     "iopub.status.idle": "2025-10-03T11:58:19.337366Z",
     "shell.execute_reply": "2025-10-03T11:58:19.336347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>samples</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>34935</td>\n",
       "      <td>0.309837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1</td>\n",
       "      <td>13882</td>\n",
       "      <td>0.123119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2</td>\n",
       "      <td>40344</td>\n",
       "      <td>0.357809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3</td>\n",
       "      <td>8532</td>\n",
       "      <td>0.075670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REM</td>\n",
       "      <td>15060</td>\n",
       "      <td>0.133566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stage  samples  proportion\n",
       "0     W    34935    0.309837\n",
       "1    N1    13882    0.123119\n",
       "2    N2    40344    0.357809\n",
       "3    N3     8532    0.075670\n",
       "4   REM    15060    0.133566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_summary = pd.DataFrame({\n",
    "    \"stage\": STAGES,\n",
    "    \"samples\": [int(class_distribution.get(idx, 0)) for idx in range(len(STAGES))]\n",
    "})\n",
    "class_summary[\"proportion\"] = class_summary[\"samples\"] / class_summary[\"samples\"].sum()\n",
    "class_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23640fdd",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f510420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:58:19.342304Z",
     "iopub.status.busy": "2025-10-03T11:58:19.341593Z",
     "iopub.status.idle": "2025-10-03T12:03:04.779258Z",
     "shell.execute_reply": "2025-10-03T12:03:04.777885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando combinacao 1/3: {'n_estimators': 240, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_samples': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando combinacao 2/3: {'n_estimators': 300, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_samples': 0.85}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando combinacao 3/3: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_samples': 0.75}\n"
     ]
    }
   ],
   "source": [
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "search_space = [\n",
    "    {\"n_estimators\": 240, \"max_depth\": 22, \"min_samples_split\": 6, \"min_samples_leaf\": 2, \"max_features\": \"sqrt\", \"max_samples\": 0.8},\n",
    "    {\"n_estimators\": 300, \"max_depth\": 26, \"min_samples_split\": 5, \"min_samples_leaf\": 2, \"max_features\": \"sqrt\", \"max_samples\": 0.85},\n",
    "    {\"n_estimators\": 200, \"max_depth\": 20, \"min_samples_split\": 8, \"min_samples_leaf\": 3, \"max_features\": \"sqrt\", \"max_samples\": 0.75}\n",
    "]\n",
    "history_records = []\n",
    "best_score = -np.inf\n",
    "best_model = None\n",
    "for idx, candidate_params in enumerate(search_space, start=1):\n",
    "    print(f\"treinando combinacao {idx}/{len(search_space)}: {candidate_params}\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=candidate_params[\"n_estimators\"],\n",
    "        max_depth=candidate_params[\"max_depth\"],\n",
    "        min_samples_split=candidate_params[\"min_samples_split\"],\n",
    "        min_samples_leaf=candidate_params[\"min_samples_leaf\"],\n",
    "        max_features=candidate_params[\"max_features\"],\n",
    "        max_samples=candidate_params[\"max_samples\"],\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=8,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    model.fit(x_train, y_train, sample_weight=train_weights)\n",
    "    val_predictions = model.predict(x_val)\n",
    "    score = f1_score(y_val, val_predictions, average=\"macro\")\n",
    "    record = dict(candidate_params)\n",
    "    record[\"val_macro_f1\"] = score\n",
    "    history_records.append(record)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "history_df = pd.DataFrame(history_records).sort_values(\"val_macro_f1\", ascending=False).reset_index(drop=True)\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbc0833",
   "metadata": {},
   "source": [
    "## Historico de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a86f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:04.785512Z",
     "iopub.status.busy": "2025-10-03T12:03:04.784984Z",
     "iopub.status.idle": "2025-10-03T12:03:04.797987Z",
     "shell.execute_reply": "2025-10-03T12:03:04.796404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>val_macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.693351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.686414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.677568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  min_samples_split  min_samples_leaf max_features  \\\n",
       "0           300         26                  5                 2         sqrt   \n",
       "1           240         22                  6                 2         sqrt   \n",
       "2           200         20                  8                 3         sqrt   \n",
       "\n",
       "   max_samples  val_macro_f1  \n",
       "0         0.85      0.693351  \n",
       "1         0.80      0.686414  \n",
       "2         0.75      0.677568  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee5ca0",
   "metadata": {},
   "source": [
    "## Avaliacao no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc96847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:04.801122Z",
     "iopub.status.busy": "2025-10-03T12:03:04.800850Z",
     "iopub.status.idle": "2025-10-03T12:03:06.597870Z",
     "shell.execute_reply": "2025-10-03T12:03:06.595953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           metric    value\n",
      "             loss 0.602668\n",
      "         accuracy 0.777747\n",
      "balanced_accuracy 0.691420\n",
      "         macro_f1 0.700113\n",
      "\n",
      "              precision  recall  f1-score  support\n",
      "W                 0.882   0.901     0.891  11429.0\n",
      "N1                0.369   0.362     0.365   3425.0\n",
      "N2                0.814   0.840     0.826  13722.0\n",
      "N3                0.782   0.707     0.742   1983.0\n",
      "REM               0.704   0.648     0.675   5319.0\n",
      "macro avg         0.710   0.691     0.700  35878.0\n",
      "weighted avg      0.775   0.778     0.776  35878.0\n",
      "\n",
      "         W    N1     N2    N3   REM\n",
      "W    10295   620    228     5   281\n",
      "N1     730  1240    870     4   581\n",
      "N2     184  1055  11520   377   586\n",
      "N3       4     4    574  1401     0\n",
      "REM    455   442    969     5  3448\n"
     ]
    }
   ],
   "source": [
    "val_predictions = model.predict(x_val)\n",
    "test_predictions = model.predict(x_test)\n",
    "test_probabilities = model.predict_proba(x_test)\n",
    "test_loss = log_loss(y_test, test_probabilities)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_balanced_acc = balanced_accuracy_score(y_test, test_predictions)\n",
    "test_macro_f1 = f1_score(y_test, test_predictions, average=\"macro\")\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"loss\", \"accuracy\", \"balanced_accuracy\", \"macro_f1\"],\n",
    "    \"value\": [test_loss, test_accuracy, test_balanced_acc, test_macro_f1]\n",
    "})\n",
    "print(summary.to_string(index=False))\n",
    "print()\n",
    "report = classification_report(y_test, test_predictions, target_names=STAGES, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_table = report_df.loc[STAGES + [\"macro avg\", \"weighted avg\"], [\"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
    "print(report_table.round(3).to_string())\n",
    "print()\n",
    "confusion = confusion_matrix(y_test, test_predictions)\n",
    "confusion_df = pd.DataFrame(confusion, index=STAGES, columns=STAGES)\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745251d0",
   "metadata": {},
   "source": [
    "## Analise adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0e3a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:06.601371Z",
     "iopub.status.busy": "2025-10-03T12:03:06.601051Z",
     "iopub.status.idle": "2025-10-03T12:03:06.748031Z",
     "shell.execute_reply": "2025-10-03T12:03:06.746140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_beta_relpow_256</th>\n",
       "      <td>0.056839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_beta_relpow_256_roll_mean_5</th>\n",
       "      <td>0.056712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_beta_relpow_256_roll_mean_10</th>\n",
       "      <td>0.053626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_beta_relpow_256</th>\n",
       "      <td>0.048923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_beta_relpow_256_roll_std_10</th>\n",
       "      <td>0.043065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_aperiodic_slope_256</th>\n",
       "      <td>0.031465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_median_1hz</th>\n",
       "      <td>0.026149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_aperiodic_slope_256</th>\n",
       "      <td>0.025837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_aperiodic_slope_256_roll_mean_15</th>\n",
       "      <td>0.025354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_median_1hz_roll_mean_5</th>\n",
       "      <td>0.025246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_beta_relpow_256_roll_std_5</th>\n",
       "      <td>0.024622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_p90_1hz_roll_mean_5</th>\n",
       "      <td>0.023494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_slow_fast_ratio_256</th>\n",
       "      <td>0.022952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_alpha_relpow_256_roll_mean_5</th>\n",
       "      <td>0.021570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_sef95_256</th>\n",
       "      <td>0.021453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_spec_entropy_256</th>\n",
       "      <td>0.018687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_delta_relpow_256</th>\n",
       "      <td>0.018399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Fpz_Cz_theta_relpow_256_roll_mean_5</th>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMG_submental_p90_1hz</th>\n",
       "      <td>0.017046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EEG_Pz_Oz_alpha_relpow_256_roll_std_10</th>\n",
       "      <td>0.016709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             importance\n",
       "EEG_Fpz_Cz_beta_relpow_256                     0.056839\n",
       "EEG_Pz_Oz_beta_relpow_256_roll_mean_5          0.056712\n",
       "EEG_Pz_Oz_beta_relpow_256_roll_mean_10         0.053626\n",
       "EEG_Pz_Oz_beta_relpow_256                      0.048923\n",
       "EEG_Pz_Oz_beta_relpow_256_roll_std_10          0.043065\n",
       "EEG_Pz_Oz_aperiodic_slope_256                  0.031465\n",
       "EMG_submental_median_1hz                       0.026149\n",
       "EEG_Fpz_Cz_aperiodic_slope_256                 0.025837\n",
       "EEG_Fpz_Cz_aperiodic_slope_256_roll_mean_15    0.025354\n",
       "EMG_submental_median_1hz_roll_mean_5           0.025246\n",
       "EEG_Pz_Oz_beta_relpow_256_roll_std_5           0.024622\n",
       "EMG_submental_p90_1hz_roll_mean_5              0.023494\n",
       "EEG_Fpz_Cz_slow_fast_ratio_256                 0.022952\n",
       "EEG_Pz_Oz_alpha_relpow_256_roll_mean_5         0.021570\n",
       "EEG_Pz_Oz_sef95_256                            0.021453\n",
       "EEG_Fpz_Cz_spec_entropy_256                    0.018687\n",
       "EEG_Fpz_Cz_delta_relpow_256                    0.018399\n",
       "EEG_Fpz_Cz_theta_relpow_256_roll_mean_5        0.018390\n",
       "EMG_submental_p90_1hz                          0.017046\n",
       "EEG_Pz_Oz_alpha_relpow_256_roll_std_10         0.016709"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.Series(model.feature_importances_, index=FEATURES)\n",
    "top_importances = importances.sort_values(ascending=False).head(20)\n",
    "top_importances.to_frame(name=\"importance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
