{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5f10be",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8cabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Balanceamento\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc0d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_features(df, subject_col=\"subject_id\", window=5):\n",
    "    df_sorted = df.sort_values([subject_col, \"epoch\"]).copy()\n",
    "    for col in df.columns:\n",
    "        if col not in [subject_col, \"epoch\", \"y\", \"stage\"]:\n",
    "            df_sorted[f\"{col}_roll_mean_{window}\"] = (\n",
    "                df_sorted.groupby(subject_col)[col]\n",
    "                .transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            )\n",
    "            df_sorted[f\"{col}_roll_max_{window}\"] = (\n",
    "                df_sorted.groupby(subject_col)[col]\n",
    "                .transform(lambda x: x.rolling(window, min_periods=1).max())\n",
    "            )\n",
    "    return df_sorted\n",
    "\n",
    "def train_random_forest(X_train, y_train, X_test, y_test, top_n=20):\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Importância das features\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    feat_sorted = feat_importances.sort_values(ascending=False)[:top_n]\n",
    "    return model, feat_sorted\n",
    "\n",
    "def gridsearch_random_forest(X, y, param_grid=None, cv=3):\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [10, 20, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    grid = GridSearchCV(rf, param_grid, cv=cv, scoring=\"f1_weighted\", n_jobs=-1, verbose=2)\n",
    "    grid.fit(X, y)\n",
    "    print(\"Melhores parâmetros:\", grid.best_params_)\n",
    "    print(\"Melhor score (f1_weighted):\", grid.best_score_)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "def add_rolling_features_sleep(df, subject_col=\"subject_id\", epoch_col=\"epoch_idx\", target_col=\"stage\", window=5):\n",
    "    df_sorted = df.sort_values(by=[subject_col, epoch_col]).copy()\n",
    "    \n",
    "    # Seleciona apenas colunas numéricas (float/int) para rolling\n",
    "    feature_cols = df_sorted.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "    feature_cols = [col for col in feature_cols if col not in [epoch_col]]\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        df_sorted[f\"{col}_roll_mean\"] = df_sorted.groupby(subject_col)[col].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean()\n",
    "        )\n",
    "        df_sorted[f\"{col}_roll_std\"] = df_sorted.groupby(subject_col)[col].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).std()\n",
    "        )\n",
    "        df_sorted[f\"{col}_roll_max\"] = df_sorted.groupby(subject_col)[col].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).max()\n",
    "        )\n",
    "        \n",
    "    return df_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079de3ae",
   "metadata": {},
   "source": [
    "Carregamento e pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c284d113",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\FIAP\\sleep-stages-classification\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1387\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1324\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'fastparquet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m DATA_DIR = BASE_DIR / \u001b[33m\"\u001b[39m\u001b[33mdatalake\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mdata-for-model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m cassette_file = DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33msleep-cassette.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df_cassette = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcassette_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfastparquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, df_cassette.shape)\n\u001b[32m     11\u001b[39m display(df_cassette.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\FIAP\\sleep-stages-classification\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\FIAP\\sleep-stages-classification\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:81\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastParquetImpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mengine must be one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\FIAP\\sleep-stages-classification\\.venv\\Lib\\site-packages\\pandas\\io\\parquet.py:302\u001b[39m, in \u001b[36mFastParquetImpl.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    300\u001b[39m     \u001b[38;5;66;03m# since pandas is a dependency of fastparquet\u001b[39;00m\n\u001b[32m    301\u001b[39m     \u001b[38;5;66;03m# we need to import on first use\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     fastparquet = \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfastparquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfastparquet is required for parquet support.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.api = fastparquet\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\FIAP\\sleep-stages-classification\\.venv\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[39m, in \u001b[36mimport_optional_dependency\u001b[39m\u001b[34m(name, extra, errors, min_version)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[2]\n",
    "DATA_DIR = BASE_DIR / \"datalake\" / \"data-for-model\"\n",
    "\n",
    "cassette_file = DATA_DIR / \"sleep-cassette.parquet\"\n",
    "df_cassette = pd.read_parquet(cassette_file, engine=\"fastparquet\")\n",
    "\n",
    "print(\"Shape:\", df_cassette.shape)\n",
    "display(df_cassette.head())\n",
    "\n",
    "print(df_cassette.info())\n",
    "print(df_cassette[\"stage\"].value_counts(normalize=True))\n",
    "print(df_cassette.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360df1c",
   "metadata": {},
   "source": [
    "Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f13f3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cassette' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mdf_cassette\u001b[49m.shape)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_cassette.info())\n\u001b[32m      4\u001b[39m sns.countplot(x=\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m, data=df_cassette)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_cassette' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df_cassette.shape)\n",
    "print(df_cassette.info())\n",
    "\n",
    "sns.countplot(x=\"stage\", data=df_cassette)\n",
    "plt.title(\"Distribuição das classes\")\n",
    "plt.show()\n",
    "\n",
    "corr = df_cassette.corr(numeric_only=True)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlação entre features\")\n",
    "plt.show()\n",
    "\n",
    "#Outputs de Resultados\n",
    "def plot_results(model, X_test, y_test, top_n=20):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "    plt.title(\"Matriz de Confusão\")\n",
    "    plt.show()\n",
    "\n",
    "    # Importância das features\n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X_test.columns)\n",
    "    feat_sorted = feat_importances.sort_values(ascending=False)[:top_n]\n",
    "    print(\"\\nTop Features:\")\n",
    "    print(feat_sorted)\n",
    "    return feat_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb243fa",
   "metadata": {},
   "source": [
    "Separação de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb220b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (28092, 28) Teste: (7024, 28)\n"
     ]
    }
   ],
   "source": [
    "X = df_cassette.drop(columns=[\"stage\", \"subject_id\", \"night_id\"], errors=\"ignore\")\n",
    "y = df_cassette[\"stage\"]\n",
    "\n",
    "# Converte colunas categóricas (se houver)\n",
    "if \"sex\" in X.columns:\n",
    "    X = pd.get_dummies(X, columns=[\"sex\"], drop_first=True)\n",
    "\n",
    "# Split treino/teste (20% teste, estratificado)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ed0e5",
   "metadata": {},
   "source": [
    "Experimentos\n",
    "\n",
    "Treino simples sem balanceamento\n",
    "Treino com rolling 10 epochs\n",
    "Treino com rolling 20 epochs\n",
    "Treino com rolling 20 epochs + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4bd11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Rolling Window: 10 epochs (sem SMOTE) ======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.76      0.45      0.57       606\n",
      "          N2       0.82      0.94      0.88      3393\n",
      "          N3       0.91      0.80      0.85      1033\n",
      "         REM       0.88      0.80      0.84      1394\n",
      "           W       0.82      0.78      0.80       598\n",
      "\n",
      "    accuracy                           0.84      7024\n",
      "   macro avg       0.84      0.76      0.79      7024\n",
      "weighted avg       0.84      0.84      0.83      7024\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.76      0.45      0.57       606\n",
      "          N2       0.82      0.94      0.88      3393\n",
      "          N3       0.91      0.80      0.85      1033\n",
      "         REM       0.88      0.80      0.84      1394\n",
      "           W       0.82      0.78      0.80       598\n",
      "\n",
      "    accuracy                           0.84      7024\n",
      "   macro avg       0.84      0.76      0.79      7024\n",
      "weighted avg       0.84      0.84      0.83      7024\n",
      "\n",
      "\n",
      "Top Features:\n",
      "EEG_Fpz_Cz_beta_relpow_256          0.034080\n",
      "EEG_Pz_Oz_beta_relpow_256           0.027326\n",
      "EEG_Pz_Oz_slow_fast_ratio_256       0.026318\n",
      "EEG_Pz_Oz_aperiodic_slope_256       0.024425\n",
      "EOG_delta_relpow_256                0.023327\n",
      "EOG_theta_relpow_256                0.022430\n",
      "EEG_Fpz_Cz_aperiodic_slope_256      0.022064\n",
      "EOG_sef95_256                       0.021118\n",
      "EOG_rms                             0.019873\n",
      "EEG_Pz_Oz_delta_relpow_256          0.019520\n",
      "EEG_Fpz_Cz_alpha_sigma_ratio_256    0.018804\n",
      "EOG_beta_relpow_256                 0.017729\n",
      "EEG_Pz_Oz_theta_alpha_ratio_256     0.017130\n",
      "EEG_Fpz_Cz_delta_theta_ratio_256    0.015969\n",
      "tso_min                             0.015573\n",
      "dtype: float64\n",
      "\n",
      "====== Rolling Window: 20 epochs (sem SMOTE) ======\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.75      0.48      0.59       606\n",
      "          N2       0.84      0.95      0.89      3393\n",
      "          N3       0.91      0.82      0.86      1033\n",
      "         REM       0.90      0.85      0.87      1394\n",
      "           W       0.83      0.77      0.80       598\n",
      "\n",
      "    accuracy                           0.85      7024\n",
      "   macro avg       0.85      0.77      0.80      7024\n",
      "weighted avg       0.85      0.85      0.85      7024\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.75      0.48      0.59       606\n",
      "          N2       0.84      0.95      0.89      3393\n",
      "          N3       0.91      0.82      0.86      1033\n",
      "         REM       0.90      0.85      0.87      1394\n",
      "           W       0.83      0.77      0.80       598\n",
      "\n",
      "    accuracy                           0.85      7024\n",
      "   macro avg       0.85      0.77      0.80      7024\n",
      "weighted avg       0.85      0.85      0.85      7024\n",
      "\n",
      "\n",
      "Top Features:\n",
      "EEG_Fpz_Cz_beta_relpow_256          0.035886\n",
      "EEG_Pz_Oz_slow_fast_ratio_256       0.029533\n",
      "EEG_Pz_Oz_beta_relpow_256           0.028482\n",
      "EEG_Pz_Oz_aperiodic_slope_256       0.026474\n",
      "EOG_sef95_256                       0.022531\n",
      "EOG_delta_relpow_256                0.022162\n",
      "EOG_theta_relpow_256                0.021646\n",
      "EOG_rms                             0.021484\n",
      "EEG_Pz_Oz_delta_relpow_256          0.019058\n",
      "EEG_Fpz_Cz_alpha_sigma_ratio_256    0.017960\n",
      "EEG_Fpz_Cz_aperiodic_slope_256      0.017786\n",
      "EEG_Pz_Oz_theta_alpha_ratio_256     0.017639\n",
      "EOG_beta_relpow_256                 0.016896\n",
      "EEG_Fpz_Cz_delta_theta_ratio_256    0.015705\n",
      "EEG_Fpz_Cz_sigma_relpow_256         0.014773\n",
      "dtype: float64\n",
      "\n",
      "===== Resumo Comparativo (sem SMOTE) =====\n",
      "Rolling 10 epochs -> Accuracy: 0.8383 | Macro F1: 0.7870 | Weighted F1: 0.8322\n",
      "Rolling 20 epochs -> Accuracy: 0.8531 | Macro F1: 0.8021 | Weighted F1: 0.8478\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# Comparação Rolling 10 vs 20\n",
    "# ======================\n",
    "\n",
    "results = {}\n",
    "\n",
    "for window in [10, 20]:\n",
    "    print(f\"\\n====== Rolling Window: {window} epochs (sem SMOTE) ======\")\n",
    "    \n",
    "    # Criar features com rolling\n",
    "    df_roll = add_rolling_features_sleep(\n",
    "        df_cassette, subject_col=\"subject_id\", epoch_col=\"epoch_idx\", window=window\n",
    "    )\n",
    "\n",
    "    # Preparar X e y\n",
    "    X_tmp = df_roll.drop(columns=[\"stage\", \"subject_id\", \"sex\", \"age\"], errors=\"ignore\")\n",
    "    X_tmp = pd.get_dummies(X_tmp, drop_first=True)\n",
    "    y_tmp = df_roll[\"stage\"]\n",
    "\n",
    "    # Tratar NaN\n",
    "    X_tmp = X_tmp.fillna(0)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tmp, y_tmp, test_size=0.2, stratify=y_tmp, random_state=42\n",
    "    )\n",
    "\n",
    "    # Treinar modelo\n",
    "    model, feat_sorted = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Avaliação\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[window] = report\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nTop Features:\")\n",
    "    print(feat_sorted.head(15))\n",
    "\n",
    "# Resumo comparativo\n",
    "print(\"\\n===== Resumo Comparativo (sem SMOTE) =====\")\n",
    "for window in [10, 20]:\n",
    "    print(f\"Rolling {window} epochs -> Accuracy: {results[window]['accuracy']:.4f} | \"\n",
    "          f\"Macro F1: {results[window]['macro avg']['f1-score']:.4f} | \"\n",
    "          f\"Weighted F1: {results[window]['weighted avg']['f1-score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "044deeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Rolling Window: 20 epochs (com SMOTE) ======\n",
      "Distribuição após SMOTE:\n",
      " stage\n",
      "W      16961\n",
      "N1     16961\n",
      "N2     16961\n",
      "N3     16961\n",
      "REM    16961\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.92      0.94      0.93      3392\n",
      "          N2       0.91      0.89      0.90      3392\n",
      "          N3       0.96      0.97      0.96      3392\n",
      "         REM       0.96      0.97      0.96      3393\n",
      "           W       0.97      0.95      0.96      3392\n",
      "\n",
      "    accuracy                           0.94     16961\n",
      "   macro avg       0.94      0.94      0.94     16961\n",
      "weighted avg       0.94      0.94      0.94     16961\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.92      0.94      0.93      3392\n",
      "          N2       0.91      0.89      0.90      3392\n",
      "          N3       0.96      0.97      0.96      3392\n",
      "         REM       0.96      0.97      0.96      3393\n",
      "           W       0.97      0.95      0.96      3392\n",
      "\n",
      "    accuracy                           0.94     16961\n",
      "   macro avg       0.94      0.94      0.94     16961\n",
      "weighted avg       0.94      0.94      0.94     16961\n",
      "\n",
      "\n",
      "Top Features:\n",
      "EEG_Pz_Oz_aperiodic_slope_256             0.039653\n",
      "EEG_Fpz_Cz_beta_relpow_256                0.038292\n",
      "EEG_Pz_Oz_beta_relpow_256                 0.033221\n",
      "EEG_Fpz_Cz_aperiodic_slope_256            0.030744\n",
      "EEG_Pz_Oz_slow_fast_ratio_256             0.026398\n",
      "EEG_Pz_Oz_theta_alpha_ratio_256           0.026033\n",
      "EEG_Pz_Oz_delta_relpow_256                0.018396\n",
      "EEG_Fpz_Cz_alpha_sigma_ratio_256          0.017688\n",
      "tso_min                                   0.017555\n",
      "EEG_Pz_Oz_aperiodic_slope_256_roll_max    0.017187\n",
      "EOG_rms                                   0.016687\n",
      "EEG_Fpz_Cz_delta_theta_ratio_256          0.016406\n",
      "tso_min_roll_mean                         0.014545\n",
      "EEG_Fpz_Cz_theta_relpow_256               0.014218\n",
      "tso_min_roll_std                          0.013772\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# Rolling 20 + SMOTE\n",
    "# ======================\n",
    "\n",
    "print(\"\\n====== Rolling Window: 20 epochs (com SMOTE) ======\")\n",
    "\n",
    "# Criar features com rolling\n",
    "df_roll = add_rolling_features_sleep(\n",
    "    df_cassette, subject_col=\"subject_id\", epoch_col=\"epoch_idx\", window=20\n",
    ")\n",
    "\n",
    "# Preparar X e y\n",
    "X_tmp = df_roll.drop(columns=[\"stage\", \"subject_id\", \"sex\", \"age\"], errors=\"ignore\")\n",
    "X_tmp = pd.get_dummies(X_tmp, drop_first=True)\n",
    "y_tmp = df_roll[\"stage\"]\n",
    "\n",
    "# Tratar NaN\n",
    "X_tmp = X_tmp.fillna(0)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_tmp, y_tmp)\n",
    "\n",
    "print(\"Distribuição após SMOTE:\\n\", pd.Series(y_res).value_counts(), \"\\n\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, y_res, test_size=0.2, stratify=y_res, random_state=42\n",
    ")\n",
    "\n",
    "# Treinar modelo\n",
    "model, feat_sorted = train_random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Avaliação\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nTop Features:\")\n",
    "print(feat_sorted.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee15e7",
   "metadata": {},
   "source": [
    "Testes com train / val / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd80784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets já separados\n",
    "BASE_PATH = Path().resolve().parents[2]\n",
    "DATASETS_PATH = BASE_PATH / \"datalake\" / \"data-for-model\"\n",
    "TRAINING_DATA_FILE = DATASETS_PATH / \"train\" / \"train_sleep_cassette.parquet\" \n",
    "VALIDATION_DATA_FILE = DATASETS_PATH / \"val\" / \"val_sleep_cassette.parquet\" \n",
    "TEST_DATA_FILE = DATASETS_PATH / \"test\" / \"test_sleep_cassette.parquet\" \n",
    "\n",
    "df_train = pd.read_parquet(TRAINING_DATA_FILE, engine=\"fastparquet\")\n",
    "df_val = pd.read_parquet(VALIDATION_DATA_FILE, engine=\"fastparquet\")\n",
    "df_test = pd.read_parquet(TEST_DATA_FILE, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1f4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Preparar dados ========\n",
    "def prepare_X_y(df):\n",
    "    X = df.drop(columns=[\"stage\", \"subject_id\", \"sex\", \"age\"], errors=\"ignore\")\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X = X.fillna(0)\n",
    "    y = df[\"stage\"]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = prepare_X_y(df_train)\n",
    "X_val, y_val = prepare_X_y(df_val)\n",
    "X_test, y_test = prepare_X_y(df_test)\n",
    "\n",
    "# Alinhar dummies\n",
    "X_train, X_val = X_train.align(X_val, join=\"left\", axis=1, fill_value=0)\n",
    "X_train, X_test = X_train.align(X_test, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "# ======== Remover NaNs do target ========\n",
    "mask = y_train.notna()\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask_val = y_val.notna()\n",
    "X_val = X_val[mask_val]\n",
    "y_val = y_val[mask_val]\n",
    "\n",
    "mask_test = y_test.notna()\n",
    "X_test = X_test[mask_test]\n",
    "y_test = y_test[mask_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "712d6905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição após SMOTE (train):\n",
      " stage\n",
      "W      42211\n",
      "N1     42211\n",
      "N2     42211\n",
      "N3     42211\n",
      "REM    42211\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.42      0.46      0.44      4527\n",
      "          N2       0.78      0.83      0.80     14715\n",
      "          N3       0.80      0.61      0.69      3549\n",
      "         REM       0.74      0.84      0.79      5257\n",
      "           W       0.87      0.75      0.80      8167\n",
      "\n",
      "    accuracy                           0.74     36215\n",
      "   macro avg       0.72      0.69      0.70     36215\n",
      "weighted avg       0.75      0.74      0.74     36215\n",
      "\n",
      "\n",
      "===== Avaliação no Validation =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.42      0.46      0.44      4527\n",
      "          N2       0.78      0.83      0.80     14715\n",
      "          N3       0.80      0.61      0.69      3549\n",
      "         REM       0.74      0.84      0.79      5257\n",
      "           W       0.87      0.75      0.80      8167\n",
      "\n",
      "    accuracy                           0.74     36215\n",
      "   macro avg       0.72      0.69      0.70     36215\n",
      "weighted avg       0.75      0.74      0.74     36215\n",
      "\n",
      "\n",
      "===== Avaliação no Test =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.37      0.40      0.39      3018\n",
      "          N2       0.79      0.80      0.80     12206\n",
      "          N3       0.77      0.71      0.74      2450\n",
      "         REM       0.71      0.73      0.72      4889\n",
      "           W       0.81      0.75      0.78      4235\n",
      "\n",
      "    accuracy                           0.73     26798\n",
      "   macro avg       0.69      0.68      0.68     26798\n",
      "weighted avg       0.73      0.73      0.73     26798\n",
      "\n",
      "\n",
      "Top Features:\n",
      "EEG_Pz_Oz_aperiodic_slope_256                 0.044314\n",
      "EEG_Fpz_Cz_beta_relpow_256                    0.041508\n",
      "EEG_Pz_Oz_beta_relpow_256_roll_mean_10        0.033037\n",
      "EEG_Fpz_Cz_beta_relpow_256_roll_mean_10       0.031056\n",
      "EEG_Pz_Oz_aperiodic_slope_256_roll_mean_10    0.030113\n",
      "EEG_Pz_Oz_beta_relpow_256                     0.029858\n",
      "EOG_delta_relpow_256_roll_max_10              0.027788\n",
      "EEG_Pz_Oz_beta_relpow_256_roll_max_10         0.025955\n",
      "EMG_submental_median_1hz_roll_max_10          0.024413\n",
      "EOG_rms                                       0.023058\n",
      "EEG_Pz_Oz_slow_fast_ratio_256                 0.022231\n",
      "EEG_Pz_Oz_aperiodic_slope_256_roll_max_10     0.022042\n",
      "EEG_Fpz_Cz_beta_relpow_256_roll_std_10        0.020968\n",
      "EMG_submental_median_1hz                      0.020905\n",
      "EMG_submental_median_1hz_roll_mean_10         0.020616\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ======== SMOTE apenas no treino ========\n",
    "smote = SMOTE(random_state=1542)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Distribuição após SMOTE (train):\\n\", pd.Series(y_train_res).value_counts(), \"\\n\")\n",
    "\n",
    "# ======== Treinar modelo COM SMOTE ========\n",
    "def train_random_forest(X_train, y_train, X_test, y_test, top_n=20):\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    feat_sorted = feat_importances.sort_values(ascending=False)\n",
    "    \n",
    "    return model, feat_sorted\n",
    "\n",
    "model, feat_sorted = train_random_forest(X_train_res, y_train_res, X_val, y_val)\n",
    "\n",
    "# ======== Avaliação ========\n",
    "print(\"\\n===== Avaliação no Validation =====\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\n===== Avaliação no Test =====\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nTop Features:\")\n",
    "print(feat_sorted.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4a8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.44      0.31      0.36      4215\n",
      "          N2       0.80      0.84      0.82     15066\n",
      "          N3       0.69      0.65      0.67      2524\n",
      "         REM       0.73      0.74      0.74      5456\n",
      "           W       0.88      0.92      0.90     15120\n",
      "\n",
      "    accuracy                           0.79     42381\n",
      "   macro avg       0.71      0.69      0.70     42381\n",
      "weighted avg       0.78      0.79      0.78     42381\n",
      "\n",
      "\n",
      "===== Avaliação no Validation =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.44      0.31      0.36      4215\n",
      "          N2       0.80      0.84      0.82     15066\n",
      "          N3       0.69      0.65      0.67      2524\n",
      "         REM       0.73      0.74      0.74      5456\n",
      "           W       0.88      0.92      0.90     15120\n",
      "\n",
      "    accuracy                           0.79     42381\n",
      "   macro avg       0.71      0.69      0.70     42381\n",
      "weighted avg       0.78      0.79      0.78     42381\n",
      "\n",
      "\n",
      "===== Avaliação no Test =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.42      0.27      0.33      3425\n",
      "          N2       0.79      0.89      0.84     13722\n",
      "          N3       0.83      0.62      0.71      1983\n",
      "         REM       0.74      0.64      0.68      5319\n",
      "           W       0.87      0.93      0.90     11429\n",
      "\n",
      "    accuracy                           0.79     35878\n",
      "   macro avg       0.73      0.67      0.69     35878\n",
      "weighted avg       0.78      0.79      0.78     35878\n",
      "\n",
      "\n",
      "Top Features:\n",
      "EEG_Pz_Oz_aperiodic_slope_256             0.057859\n",
      "EEG_Pz_Oz_beta_relpow_256_roll_mean_5     0.055628\n",
      "EEG_Pz_Oz_beta_relpow_256                 0.045056\n",
      "EEG_Pz_Oz_beta_relpow_256_roll_mean_10    0.034905\n",
      "EEG_Fpz_Cz_aperiodic_slope_256            0.031593\n",
      "EOG_rms                                   0.030790\n",
      "EOG_rms_roll_mean_5                       0.029659\n",
      "EEG_Fpz_Cz_beta_relpow_256                0.025046\n",
      "EOG_rms_roll_std_5                        0.024236\n",
      "EEG_Pz_Oz_sef95_256                       0.023947\n",
      "EMG_submental_median_1hz                  0.022639\n",
      "EOG_rms_roll_mean_10                      0.021824\n",
      "EMG_submental_median_1hz_roll_mean_5      0.021650\n",
      "EEG_Pz_Oz_delta_relpow_256                0.020818\n",
      "EEG_Pz_Oz_alpha_relpow_256_roll_mean_5    0.020740\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ======== Treinar modelo SEM SMOTE ========\n",
    "def train_random_forest(X_train, y_train, X_test, y_test, top_n=20):\n",
    "    model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    feat_sorted = feat_importances.sort_values(ascending=False)\n",
    "    \n",
    "    return model, feat_sorted\n",
    "\n",
    "model, feat_sorted = train_random_forest(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# ======== Avaliação ========\n",
    "print(\"\\n===== Avaliação no Validation =====\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\n===== Avaliação no Test =====\")\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nTop Features:\")\n",
    "print(feat_sorted.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d2e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: C:\\Python\\FIAP\\sleep-stages-classification\\final-models\\random-forest-model.pkl\n"
     ]
    }
   ],
   "source": [
    "# ======== Salvar modelo de forma compacta ========\n",
    "import joblib\n",
    "\n",
    "FINAL_MODELS_PATH = BASE_PATH / \"final-models\" \n",
    "MODEL_FILENAME = FINAL_MODELS_PATH / \"random-forest-model.pkl\"\n",
    "\n",
    "explainer_package = {\n",
    "    \"model\": model,\n",
    "    \"features\": X_train.columns.tolist(),\n",
    "    \"target\": y_train.name if hasattr(y_train, \"name\") else \"target\"\n",
    "}\n",
    "\n",
    "# Salvar com compressão em XZ\n",
    "joblib.dump(explainer_package, MODEL_FILENAME, compress=(\"xz\", 3))\n",
    "\n",
    "print(f\"Modelo salvo em: {MODEL_FILENAME}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
